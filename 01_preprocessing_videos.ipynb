{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e97334-1661-4797-b7a7-688f9af5b8e7",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Videos\n",
    "\n",
    "This notebook focuses on the image preprocessing steps for the model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556533a-e857-4de6-aa92-70a356dc7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7270fc6-613c-4a19-9ea1-90e5640f30a4",
   "metadata": {},
   "source": [
    "## Extracting Landmarks from Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57419f-d107-480a-af61-32624843c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.video_preprocessing import extract_landmarks_from_videos\n",
    "\n",
    "video_path = 'data/external/source-lk'\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    extract_landmarks_from_videos(video_path)\n",
    "else:\n",
    "    print(\"Path does not exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a89afa9-d288-4ada-b5c6-223c12cfedee",
   "metadata": {},
   "source": [
    "## Extracting Audio Features using Librosa\n",
    "\n",
    "Librosa lets you extract audio features and add more context to the dance gestures analysis.\n",
    "\n",
    "* Tempo and Beat Times are important audio features that can be used to identify the rhythmic structure and timing of the music in a dance video.\n",
    "* Full Signal tells us about the sound of the performance, including tempo, rhythm, and melody. This helps us understand how the music and dance movements are synchronized.\n",
    "* Percussive signal shows us the timing of the dance movements and how they relate to the beat of the music, helping us identify accents. (Behavioral Gestures)\n",
    "* Harmonic Signal tells us about the emotional and expressive elements of the performance. (Expressive Gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb36438-9d7e-4bdb-a73b-377231c1d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.audio import extract_tempo_and_beats\n",
    "\n",
    "video_url_path = \"./data/external/contemporary_001.mp4\"\n",
    "tempo, beat_times = extract_tempo_and_beats(video_url_path)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, figsize=(24, 12))\n",
    "y, sr = librosa.load(video_url_path)\n",
    "y_harm, y_perc = librosa.effects.hpss(y)\n",
    "librosa.display.waveshow(y, sr=sr, color='r', alpha=0.5, ax=ax[0], marker='.', label='Full signal')\n",
    "librosa.display.waveshow(y_harm, sr=sr, color='g', alpha=0.5, ax=ax[1], label='Harmonic')\n",
    "librosa.display.waveshow(y_perc, sr=sr, color='b', alpha=0.5, ax=ax[2], label='Percussive')\n",
    "for i in range(2):\n",
    "    ax[i].set_xlim(2,31)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xticks(np.arange(1, 30, 1))\n",
    "    ax[i].grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26ea5c-e24c-41e7-a061-908e07af1360",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* https://github.com/kayesokua/gestures/blob/main/references/README.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
